"""
SwarmController
===============

Coordinates a fleet of Cursor GUI / headless agents, dispatching work from a
central `TaskNexus`, collecting results via an in-process `EventBus`, feeding
them to `FeedbackEngineV2`, and persisting lore for Dream.OS.

Key refactors
-------------
*   **Config-first** â€“ everything comes from one `AppConfig`.
*   **Single EventType source** â€“ avoid accidental shadowing.
*   **Clean imports** â€“ drop unused stdlib & package names.
*   **Graceful shutdown** â€“ join worker threads.
*   **Quieter logs** â€“ debug for tight loops, info for milestones.
"""

from __future__ import annotations

import asyncio
import datetime as _dt
import importlib
import json
import logging
import os
import random
import re
import subprocess
import sys
import threading
import time
from pathlib import Path
from typing import Any, Dict, List, Optional

from _agent_coordination.tools.event_bus import EventBus
from _agent_coordination.tools.event_type import EventType  # â† single source-of-truth

from dreamos.agents.agent2_infra_surgeon import Agent2InfraSurgeon
from dreamos.agents.chatgpt_web_agent import run_loop as chat_run_loop
from dreamos.coordination.project_board_manager import ProjectBoardManager
from dreamos.core.config import AppConfig
from dreamos.core.tasks.nexus.task_nexus import TaskNexus
from dreamos.feedback.feedback_engine_v2 import FeedbackEngineV2
from dreamos.hooks.stats_logger import StatsLoggingHook

from ...channels.local_blob_channel import LocalBlobChannel
from ...core.coordination.base_agent import TaskStatus
from .cursor_fleet_launcher import (
    assign_windows_to_monitors,
    get_cursor_windows,
    launch_cursor_instance,
)
from .virtual_desktop_runner import VirtualDesktopController

logger = logging.getLogger(__name__)  # logging configured by entry point


class SwarmController:
    """Top-level coordinator for Cursor agents (GUI & headless)."""

    _DEFAULT_STATS_INTERVAL_SEC: int = 60

    # --------------------------------------------------------------------- #
    # Construction
    # --------------------------------------------------------------------- #
    def __init__(self, config: AppConfig) -> None:
        self.config: AppConfig = config

        # -- fleet & channel ------------------------------------------------
        self.fleet_size: int = getattr(config.swarm, "fleet_size", 3)

        azure_conf = getattr(config.integrations, "azure_blob", None)
        self.container_name: str = getattr(azure_conf, "container_name", "dream-os-c2")
        self.sas_token: Optional[str] = getattr(azure_conf, "sas_token", None)
        self.connection_string: Optional[str] = getattr(
            azure_conf, "connection_string", None
        )
        self.use_local: bool = getattr(config.memory_channel, "use_local_blob", False)

        if not self.use_local and not (self.connection_string or self.sas_token):
            logger.warning(
                "ðŸ’¾ Azure Blob not fully configured; falling back to LocalBlobChannel."
            )
            self.use_local = True

        self.channel = LocalBlobChannel()
        if not self.channel.healthcheck():
            raise RuntimeError("LocalBlobChannel health-check failed â€“ aborting")

        # -- runtime components --------------------------------------------
        self.nexus = TaskNexus(config=self.config, task_file="runtime/task_list.json")
        self.stats_hook = StatsLoggingHook(self.nexus)
        self.event_bus = EventBus()
        self.event_bus.subscribe(EventType.TASK_COMPLETED.value, self._handle_result)

        # -- orchestration state -------------------------------------------
        self._stop_event = threading.Event()
        self.workers: List[threading.Thread] = []

        # -- background stats ----------------------------------------------
        stats_ivl = getattr(
            config.monitoring, "stats_interval", self._DEFAULT_STATS_INTERVAL_SEC
        )
        self._start_stats_autologger(interval=stats_ivl)

    # --------------------------------------------------------------------- #
    # Public API
    # --------------------------------------------------------------------- #
    def start(self, initial_tasks: Optional[List[Dict[str, Any]]] = None) -> None:
        """Bring up chat-producer, GUI agents, headless workers, then begin routing loop."""
        logger.info(f"ðŸš€ SwarmController booting {self.fleet_size} agents")

        # 0) ChatGPT Web-agent (producer)
        self._spawn_thread(
            target=chat_run_loop,
            args=(self._stop_event,),
            name="ChatGPTWebAgent",
        )

        # 1) Seed TaskNexus
        for task in initial_tasks or []:
            self.nexus.add_task(task)
            logger.info(f"ðŸ“¥ Seed task queued â†’ {task.get('id', task)[:60]}")

        # 2) GUI Cursor processes
        processes = [launch_cursor_instance(i) for i in range(self.fleet_size)]
        time.sleep(0.5)  # allow windows to surface

        try:
            windows = get_cursor_windows(target_count=len(processes), timeout=30)
            assign_windows_to_monitors(windows)
        except Exception as tiling_err:  # pylint: disable=broad-except
            logger.warning(f"ðŸªŸ Window tiling skipped: {tiling_err}")

        # 3) Headless workers
        for i in range(self.fleet_size):
            self._spawn_thread(target=self._worker_loop, name=f"Worker-{i+1}")

        # 4) Routing loop (blocking)
        self._route_loop()

    def shutdown(self) -> None:
        """Signal workers to stop then join threads."""
        logger.info("ðŸ›‘ SwarmController shutdown initiated")
        self._stop_event.set()

        for t in self.workers:
            t.join(timeout=5)

        logger.info("âœ… SwarmController shutdown complete")

    # --------------------------------------------------------------------- #
    # Internal helpers
    # --------------------------------------------------------------------- #
    def _spawn_thread(self, *, target, args: tuple = (), name: str) -> None:
        th = threading.Thread(target=target, args=args, name=name, daemon=True)
        th.start()
        self.workers.append(th)

    # .........................................
    # Worker
    # .........................................
    def _worker_loop(self) -> None:
        """Instantiate and run a dedicated agent instance (e.g., Agent2)."""
        worker_name = threading.current_thread().name
        logger.info(f"Worker thread {worker_name} starting.")

        try:
            # Run the async part of the worker loop
            asyncio.run(self._run_agent_async(worker_name))
        except Exception as e:
            logger.critical(
                f"[{worker_name}] CRITICAL ASYNC RUNNER ERROR: {e}", exc_info=True
            )
        finally:
            logger.info(f"Worker thread {worker_name} finished.")

    async def _run_agent_async(self, worker_name: str) -> None:
        """Asynchronous part of the worker loop: instantiate and run agent."""
        # Attempt to launch headless Cursor in a virtual desktop
        # self._maybe_launch_headless_cursor() # Keep this if needed for the agent

        # --- Agent Instantiation ---
        agent_instance = None
        agent_config_found = False
        try:
            # Iterate through configured activations
            for activation_conf in self.config.swarm.active_agents:
                # Check if the worker_name matches the pattern
                if re.fullmatch(activation_conf.worker_id_pattern, worker_name):
                    agent_config_found = True
                    logger.info(
                        f"[{worker_name}] Matched activation config: {activation_conf.agent_module}.{activation_conf.agent_class}"
                    )

                    # Dynamically import the module
                    try:
                        module_path = activation_conf.agent_module
                        module = importlib.import_module(module_path)
                    except ImportError as e:
                        logger.critical(
                            f"[{worker_name}] Failed to import agent module {module_path}: {e}"
                        )
                        return  # Cannot proceed

                    # Get the class from the module
                    try:
                        AgentClass = getattr(module, activation_conf.agent_class)
                    except AttributeError:
                        logger.critical(
                            f"[{worker_name}] Agent class {activation_conf.agent_class} not found in module {module_path}."
                        )
                        return  # Cannot proceed

                    # Prepare arguments for instantiation (common args)
                    # Specific agents might need more/different args - requires more complex config or introspection
                    agent_id = (
                        activation_conf.agent_id_override
                        or f"{activation_conf.agent_class}_{worker_name}"
                    )
                    agent_args = {
                        "agent_id": agent_id,
                        "config": self.config,
                        "agent_bus": self.event_bus,
                        # Conditionally add PBM if the agent expects it (best effort)
                        # A better approach might involve dependency injection or capability checks
                    }
                    if (
                        hasattr(AgentClass, "__init__")
                        and "pbm" in AgentClass.__init__.__code__.co_varnames
                    ):
                        if not self.nexus or not self.nexus.board_manager:
                            logger.error(
                                f"[{worker_name}] Agent {AgentClass.__name__} requires PBM, but it's not available in TaskNexus."
                            )
                            # Decide how to handle: skip agent, raise error?
                            # For now, skip instantiation if PBM is required but missing.
                            return
                        agent_args["pbm"] = self.nexus.board_manager

                    # Instantiate the agent
                    logger.info(
                        f"[{worker_name}] Instantiating {AgentClass.__name__} with ID {agent_id}..."
                    )
                    agent_instance = AgentClass(**agent_args)
                    logger.info(
                        f"[{worker_name}] Successfully instantiated {agent_id}."
                    )
                    break  # Stop after finding the first matching config

            if not agent_config_found:
                logger.warning(
                    f"[{worker_name}] No activation config found for this worker. Skipping agent instantiation."
                )
                return

        except Exception as e:
            logger.critical(
                f"[{worker_name}] CRITICAL ERROR instantiating agent: {e}",
                exc_info=True,
            )
            return  # Cannot proceed without an agent instance

        # --- Run Agent's Autonomous Loop ---
        if not agent_instance:
            logger.error(
                f"[{worker_name}] Agent instance not created. Cannot run loop."
            )
            return

        logger.info(
            f"[{worker_name}] Starting agent {agent_instance.agent_id}'s autonomous loop..."
        )
        agent_task = None
        try:
            # Create a task for the agent's loop - asyncio.run provides the loop
            if not hasattr(
                agent_instance, "run_autonomous_loop"
            ) or not asyncio.iscoroutinefunction(agent_instance.run_autonomous_loop):
                logger.error(
                    f"[{worker_name}] Agent {agent_instance.agent_id} does not have a valid async 'run_autonomous_loop' method."
                )
                return
            agent_task = asyncio.create_task(agent_instance.run_autonomous_loop())

            # Monitor the stop event and cancel the agent task if needed
            while not self._stop_event.is_set():
                if agent_task.done():
                    logger.info(
                        f"[{worker_name}] Agent {agent_instance.agent_id} loop task finished unexpectedly."
                    )
                    # Check for exceptions
                    exc = agent_task.exception()
                    if exc:
                        logger.error(
                            f"[{worker_name}] Agent loop task finished with error: {exc}",
                            exc_info=exc,
                        )
                    break  # Exit worker loop if agent loop finishes

                # Yield control while checking stop event periodically
                try:
                    # wait_for ensures sleep doesn't block cancellation indefinitely
                    await asyncio.wait_for(asyncio.sleep(1), timeout=1.1)
                except asyncio.TimeoutError:
                    pass  # Expected if sleep completes

            # If stop event is set, cancel the agent task gracefully
            if self._stop_event.is_set():
                if agent_task and not agent_task.done():
                    logger.info(
                        f"[{worker_name}] Stop event set. Cancelling agent {agent_instance.agent_id} loop..."
                    )
                    agent_task.cancel()
                    try:
                        # Wait briefly for cancellation to propagate
                        await asyncio.wait_for(agent_task, timeout=5.0)
                    except asyncio.CancelledError:
                        logger.info(
                            f"[{worker_name}] Agent {agent_instance.agent_id} loop successfully cancelled."
                        )
                    except asyncio.TimeoutError:
                        logger.warning(
                            f"[{worker_name}] Timeout waiting for agent {agent_instance.agent_id} loop cancellation."
                        )
                    except Exception as e:
                        logger.error(
                            f"[{worker_name}] Error during agent task cancellation/cleanup: {e}",
                            exc_info=True,
                        )

        except Exception as e:
            logger.exception(f"[{worker_name}] Unhandled error running agent loop: {e}")
        finally:
            logger.debug(f"[{worker_name}] Agent async runner finishing.")

    def _maybe_launch_headless_cursor(self) -> None:
        """Launch headless Cursor if path exists, else continue silently."""
        cursor_cfg = getattr(self.config.tools, "cursor", None)
        cursor_exe = getattr(cursor_cfg, "executable_path", "Cursor.exe")

        if not Path(cursor_exe).exists():
            logger.warning(
                f"Cursor exe not found at '{cursor_exe}', skipping headless launch"
            )
            return

        try:
            VirtualDesktopController().launch_cursor_headless(
                cursor_exe_path=cursor_exe
            )
            logger.info(f"ðŸ–¥ï¸  Headless Cursor launched â†’ {cursor_exe}")
        except Exception as vdc_err:  # pylint: disable=broad-except
            logger.warning(f"Headless launch failed: {vdc_err}")

    # --------------------------------------------------------------------- #
    # Router
    # --------------------------------------------------------------------- #
    def _route_loop(self) -> None:
        """Idle loop so main thread can honour Ctrl-C & run atexit hooks."""
        logger.info("ðŸ“¡ Routing loop active â€“ Ctrl-C to exit")
        try:
            while not self._stop_event.is_set():
                time.sleep(5)
        except KeyboardInterrupt:
            logger.info("KeyboardInterrupt received â€“ shutting down")
        finally:
            self.shutdown()

    # --------------------------------------------------------------------- #
    # Result Handler
    # --------------------------------------------------------------------- #
    def _handle_result(self, result: Dict[str, Any]) -> None:
        """Handle result â†’ feedback â†’ lore persistence."""
        logger.info(f"ðŸ“‘ Result received for {result.get('id')}")
        self._run_feedback_engine(result)
        self._persist_lore_metadata(result)
        self._compile_lore()

    # ------------------------------------------------------------------ #
    # Feedback / Lore helpers
    # ------------------------------------------------------------------ #
    def _run_feedback_engine(self, result: Dict[str, Any]) -> None:
        try:
            fe = FeedbackEngineV2(config=self.config)
            analyses = asyncio.run(fe.analyze_failures())
            if analyses:
                out_dir = Path("dream_logs/feedback")
                out_dir.mkdir(parents=True, exist_ok=True)
                out_file = out_dir / f"failure_analysis_{result['id']}.json"
                fe.save_analysis(analyses, output_file=str(out_file))
                logger.info(f"ðŸ” Feedback saved â†’ {out_file}")
        except Exception as fe_err:  # pylint: disable=broad-except
            logger.error(f"FeedbackEngineV2 failed: {fe_err}", exc_info=True)

    def _persist_lore_metadata(self, result: Dict[str, Any]) -> None:
        try:
            task_list_path = Path("runtime/task_list.json")
            if not task_list_path.exists():
                logger.warning(
                    f"Lore metadata persistence skipped: {task_list_path} not found."
                )
                return
            tasks = json.loads(task_list_path.read_text(encoding="utf-8"))
            for t in tasks:
                if t.get("id") == result["id"]:
                    payload = t.setdefault("payload", {})
                    payload["modified_files"] = result.get("modified_files", [])
                    stdout = result.get("stdout", "")
                    payload["log_tail"] = "\n".join(stdout.strip().splitlines()[-10:])
            task_list_path.write_text(json.dumps(tasks, indent=2), encoding="utf-8")
        except Exception as lore_err:  # pylint: disable=broad-except
            logger.warning(f"Lore metadata persistence failed: {lore_err}")

    def _compile_lore(self) -> None:
        try:
            script = Path("_agent_coordination/tools/compile_lore.py")
            if not script.exists():
                logger.warning(
                    f"Lore compilation skipped: Script not found at {script}"
                )
                return
            subprocess.run(
                [
                    sys.executable,
                    str(script),
                    "--style",
                    "devlog",
                    "--translation",
                    "dream_logs/config/dream_translation.yaml",
                    "--tasks",
                    "runtime/task_list.json",
                ],
                check=True,
            )
            logger.debug("Lore compiled")
        except Exception as comp_err:  # pylint: disable=broad-except
            logger.error(f"Lore compilation failed: {comp_err}", exc_info=True)

    # ------------------------------------------------------------------ #
    # Stats helper
    # ------------------------------------------------------------------ #
    def _start_stats_autologger(self, interval: int) -> None:
        self._spawn_thread(
            target=self._stats_loop,
            args=(interval,),
            name="StatsAutoLogger",
        )

    def _stats_loop(self, interval: int) -> None:
        while not self._stop_event.is_set():
            try:
                self.stats_hook.log_snapshot()
                print(f"ðŸ“Š Stats @ {_dt.datetime.utcnow().isoformat()}Z")
            except Exception as stats_err:  # pylint: disable=broad-except
                logger.error(f"Stats logging failed: {stats_err}", exc_info=True)
            time.sleep(interval)
